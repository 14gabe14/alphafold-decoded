{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "of_basic_features = torch.load('kilian/basic_features.pt', map_location='cpu')\n",
    "of_extra_msa_feat = torch.load('kilian/extra_msa_feat.pt', map_location='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### target_feat\n",
    "This is a feature of size [$N_{res}$ , 21] consisting of the “aatype” feature.\n",
    "- One-hot representation of the input amino acid sequence (20 amino\n",
    "acids + unknown).\n",
    "This feature is padded in openfold in data_transforms: make_msa_feat(), so it has shape [$N_{res}$, 22]\n",
    "For now, we simulate this with an additional letter Z in the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = 'PIAQIHILEGRSDEQKETLIREVSEAISRSLDAPLTSVRVIITEMAKGHFGIGGELASK'\n",
    "\n",
    "\n",
    "def calculate_target_feat(sequence):\n",
    "    aa_codes = \"ZARNDCQEGHILKMFPSTWYVX\"\n",
    "    sequence_inds = torch.tensor([aa_codes.index(a) for a in sequence])\n",
    "    encoding = nn.functional.one_hot(sequence_inds, num_classes=22)\n",
    "    return encoding\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### residue_index\n",
    "This is a feature of size [$N_{res}$] consisting of the \"residue_index\" feature\n",
    "- index into the original amino acid sequence, in our case just [0, ..., $N_{res}$]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_residue_index(sequence):\n",
    "    return torch.arange(len(sequence))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### msa_feat\n",
    "This is a feature of size [$N_{clust}$, $N_{res}$, 49] constructed by concatenating \"cluster_msa\", \"cluster_has_deletion\", \"cluster_deletion_value\", \"cluster_deletion_mean\", \"cluster_profile\".\n",
    "- This feature seems to be sampled randomly during recycling, this isn't implemented yet\n",
    "- \"cluster_msa\" of shape [$N_{clust}$, $N_{res}$, 23] is a one-hot representation of the cluster centers.\n",
    "- \"cluster_has_deletion\" of shape [$N_{clust}$, $N_{res}$, 1] is a binary feature indicating if there is a deletion to the left of the residue in the MSA cluster centres\n",
    "- \"cluster_deletion_value\"..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfold.np import residue_constants\n",
    "\n",
    "def load_a3m_file(file_name):\n",
    "    with open(file_name, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    description_line_indices = [i for i,l in enumerate(lines) if l.startswith('>')]\n",
    "    descriptions = [lines[i].strip() for i in description_line_indices]\n",
    "    seqs = [lines[i+1].strip() for i in description_line_indices]\n",
    "    unique_seqs = []\n",
    "\n",
    "    deletion_count_matrix = []\n",
    "    for seq in seqs:\n",
    "        deletion_count_list = []\n",
    "        deletion_counter = 0\n",
    "        for letter in seq:\n",
    "            if letter.islower():\n",
    "                deletion_counter += 1\n",
    "            else:\n",
    "                deletion_count_list.append(deletion_counter)\n",
    "                deletion_counter = 0\n",
    "        seq_without_deletion = re.sub('[a-z]', '', seq)\n",
    "        if seq_without_deletion in unique_seqs:\n",
    "            continue\n",
    "        \n",
    "        unique_seqs.append(seq_without_deletion)\n",
    "        deletion_count_matrix.append(deletion_count_list)\n",
    "\n",
    "    aa_codes = \"ARNDCQEGHILKMFPSTWYVX-\"\n",
    "    unique_seqs = torch.stack([\n",
    "            torch.tensor([aa_codes.index(a) for a in seq]) \n",
    "        for seq in unique_seqs])\n",
    "    unique_seqs_one_hot = nn.functional.one_hot(unique_seqs, num_classes=22)\n",
    "    amino_acid_distribution = unique_seqs_one_hot.float().mean(dim=0)\n",
    "    deletion_count_matrix = torch.tensor(deletion_count_matrix)\n",
    "    \n",
    "    return { 'msa_aatype': unique_seqs, 'msa_deletion_count': deletion_count_matrix, 'amino_acid_distribution': amino_acid_distribution}\n",
    "\n",
    "# features = load_a3m_file('kilian/alignments_hhr/test_tautomerase/test_tautomerase.a3m')\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_clusters(features, max_msa_clusters=512, basic_seed=0):\n",
    "    sequences = features['msa_aatype']\n",
    "    num_seqs = sequences.shape[0]\n",
    "    max_msa_clusters = min(max_msa_clusters, num_seqs)\n",
    "    random_generator = torch.Generator(device=sequences.device)\n",
    "    random_generator.manual_seed(basic_seed)\n",
    "    shuffled = torch.randperm(num_seqs-1, generator=random_generator)+1\n",
    "    shuffled = torch.cat((torch.tensor([0]), shuffled), dim=0)\n",
    "\n",
    "    resulting_features = {key: value.clone() for key, value in features.items()}\n",
    "    MSA_FEATURE_NAMES = ['msa_aatype', 'msa_deletion_count']\n",
    "    for key in MSA_FEATURE_NAMES:\n",
    "        if key not in features:\n",
    "            continue\n",
    "        feature = features[key]\n",
    "        resulting_features = {\n",
    "            **resulting_features, \n",
    "            key: feature[shuffled[:max_msa_clusters]],\n",
    "            f'extra_{key}': feature[shuffled[max_msa_clusters:]] \n",
    "        }\n",
    "    return resulting_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributions as distributions\n",
    "def mask_clusters(features, mask_probability=0.15, basic_seed=0):\n",
    "    features = {key: value.clone() for key, value in features.items()}\n",
    "    N_clust, N_res = features['msa_aatype'].shape\n",
    "    N_aa_categories = 23 # 20 Amino Acids, Unknown Amino Acid, Gap, masked_msa_token\n",
    "    odds = {\n",
    "        'uniform_replacement': 0.1,\n",
    "        'replacement_from_distribution': 0.1,\n",
    "        'no_replacement': 0.1,\n",
    "        'masked_out': 0.7\n",
    "    }\n",
    "    uniform_category = torch.tensor([1/20] * 20 + [0, 0]) * odds['uniform_replacement']\n",
    "    replacement_from_distribution = features['amino_acid_distribution'] * odds['replacement_from_distribution']\n",
    "    no_replacement = nn.functional.one_hot(features['msa_aatype'], num_classes=22) * odds['no_replacement']\n",
    "    masked_out = torch.tensor([odds['masked_out']]).expand((N_clust, N_res, 1))\n",
    "\n",
    "    transition_categories_without_mask = uniform_category + replacement_from_distribution + no_replacement\n",
    "    transition_categories = torch.cat((transition_categories_without_mask, masked_out), dim=-1)\n",
    "    unk_in_msa = features['msa_aatype'] == 20\n",
    "\n",
    "\n",
    "    gen = torch.Generator(device=features['msa_aatype'].device)\n",
    "    gen.manual_seed(basic_seed+1)\n",
    "    mask = torch.rand(features['msa_aatype'].shape, generator=gen) < mask_probability\n",
    "\n",
    "    torch.manual_seed(basic_seed+1)\n",
    "    replacement = distributions.Categorical(probs=transition_categories.reshape(-1, N_aa_categories)).sample()\n",
    "    replacement = replacement.reshape(N_clust, N_res)\n",
    "    features['true_msa_aatype'] = features['msa_aatype'].clone()\n",
    "    features['msa_aatype'][mask] = replacement[mask]\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_assignment(features):\n",
    "    N_clust, N_res = features['msa_aatype'].shape\n",
    "    N_extra, _ = features['extra_msa_aatype'].shape\n",
    "\n",
    "    msa_broadcast = features['msa_aatype'].reshape((N_clust, N_res, 1))\n",
    "    extra_broadcast = features['extra_msa_aatype'].T.reshape((1, N_res, N_extra))\n",
    "    mask = torch.logical_and(msa_broadcast != 22, msa_broadcast != 21)\n",
    "    agreement = torch.logical_and(msa_broadcast == extra_broadcast, mask).sum(dim=1)\n",
    "    assignment = torch.argmax(agreement, dim=0)\n",
    "    features['extra_cluster_assignment'] = assignment\n",
    "           \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_clusters(features):\n",
    "    N_clust, N_res = features['msa_aatype'].shape\n",
    "    N_extra, _ = features['extra_msa_aatype'].shape\n",
    "    assignment = features['extra_cluster_assignment']\n",
    "    assignment_counts = (torch.arange(N_clust).reshape(N_clust, 1) == assignment.reshape(1, N_extra)).sum(dim=1) + 1\n",
    "\n",
    "    def cluster_average(feature, extra_feature):\n",
    "        unsqueezed_shape = [-1] + [1] * (extra_feature.ndim-1)\n",
    "        broadcast_assignment = assignment.reshape(unsqueezed_shape).expand(extra_feature.shape)\n",
    "        result = torch.scatter_add(feature, 0, broadcast_assignment, extra_feature)\n",
    "        return result / assignment_counts.reshape(unsqueezed_shape)\n",
    "\n",
    "    cluster_deletion_mean = cluster_average(features['msa_deletion_count'], features['extra_msa_deletion_count'])\n",
    "    cluster_deletion_mean = 2/torch.pi * torch.arctan(cluster_deletion_mean / 3)\n",
    "\n",
    "    msa_one_hot = nn.functional.one_hot(features['msa_aatype'], num_classes=23)\n",
    "    extra_msa_one_hot = nn.functional.one_hot(features['extra_msa_aatype'], num_classes=23)\n",
    "    cluster_profile = cluster_average(msa_one_hot, extra_msa_one_hot)\n",
    "\n",
    "    features['cluster_deletion_mean'] = cluster_deletion_mean\n",
    "    features['cluster_profile'] = cluster_profile\n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_extra_msa(features, max_extra_msa_count=5120, basic_seed=0):\n",
    "    N_extra = features['extra_msa_aatype'].shape[0]\n",
    "    gen = torch.Generator(features['extra_msa_aatype'].device)\n",
    "    gen.manual_seed(basic_seed+2)\n",
    "    inds_to_select = torch.randperm(N_extra, generator=gen)[:max_extra_msa_count]\n",
    "    for k,v in features.items():\n",
    "        if 'extra_' in k:\n",
    "            features[k] = features[k][inds_to_select]\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_msa_feat(features):\n",
    "    N_clust, N_res = features['msa_aatype'].shape\n",
    "\n",
    "    cluster_msa = nn.functional.one_hot(features['msa_aatype'], num_classes=23)\n",
    "\n",
    "    cluster_has_deletion = (features['msa_deletion_count'] > 0).float()\n",
    "    cluster_has_deletion = cluster_has_deletion.reshape(N_clust, N_res, 1)\n",
    "\n",
    "    cluster_deletion_value = 2/torch.pi * torch.arctan(features['msa_deletion_count'] / 3)\n",
    "    cluster_deletion_value = cluster_deletion_value.reshape(N_clust, N_res, 1)\n",
    "\n",
    "    cluster_deletion_mean = features['cluster_deletion_mean']\n",
    "    cluster_deletion_mean = cluster_deletion_mean.reshape(N_clust, N_res, 1)\n",
    "    cluster_profile = features['cluster_profile']\n",
    "\n",
    "    msa_feat = torch.cat((cluster_msa, cluster_has_deletion, cluster_deletion_value, cluster_profile, cluster_deletion_mean), dim=-1)\n",
    "    return msa_feat\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_extra_msa_feat(features):\n",
    "    N_extra, N_res = features['extra_msa_aatype'].shape\n",
    "\n",
    "    extra_msa = nn.functional.one_hot(features['extra_msa_aatype'], num_classes=23)\n",
    "    extra_msa_has_deletion = (features['extra_msa_deletion_count'] > 0).float()\n",
    "    extra_msa_has_deletion = extra_msa_has_deletion.reshape(N_extra, N_res, 1)\n",
    "    extra_msa_deletion_value = 2/torch.pi * torch.arctan(features['extra_msa_deletion_count']/3)\n",
    "    extra_msa_deletion_value = extra_msa_deletion_value.reshape(N_extra, N_res, 1)\n",
    "\n",
    "    return torch.cat((extra_msa, extra_msa_has_deletion, extra_msa_deletion_value), dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_data = load_a3m_file('kilian/alignments_hhr/test_tautomerase/test_tautomerase.a3m')\n",
    "msa_feats = []\n",
    "extra_msa_feats = []\n",
    "for i in range(4):\n",
    "    features = split_clusters(seq_data, basic_seed=i)\n",
    "    features = mask_clusters(features, basic_seed=i)\n",
    "    features = cluster_assignment(features)\n",
    "    features = summarize_clusters(features)\n",
    "    features = crop_extra_msa(features, basic_seed=i)\n",
    "    msa_feat = calculate_msa_feat(features)\n",
    "    extra_msa_feat = calculate_extra_msa_feat(features)\n",
    "\n",
    "    msa_feats.append(msa_feat)\n",
    "    extra_msa_feats.append(extra_msa_feat)\n",
    "\n",
    "target_feat = calculate_target_feat(sequence)\n",
    "residue_index = calculate_residue_index(sequence)\n",
    "\n",
    "msa_feat = torch.stack(msa_feats, dim=-1)\n",
    "extra_msa_feat = torch.stack(extra_msa_feats, dim=-1)\n",
    "target_feat = target_feat.view(target_feat.shape+(1,)).broadcast_to(target_feat.shape+(4,))\n",
    "residue_index = residue_index.view(residue_index.shape+(1,)).broadcast_to(residue_index.shape+(4,))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msa_feat:\n",
      "tensor(4.1582e-09)\n",
      "target_feat:\n",
      "tensor(0.)\n",
      "residue index:\n",
      "tensor(0.)\n",
      "extra_msa_feat:\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "print('msa_feat:')\n",
    "print((msa_feat - of_basic_features['msa_feat']).abs().mean())\n",
    "print('target_feat:')\n",
    "print((target_feat - of_basic_features['target_feat']).abs().mean())\n",
    "print('residue index:')\n",
    "print((residue_index - of_basic_features['residue_index']).float().abs().mean())\n",
    "print('extra_msa_feat:')\n",
    "print((extra_msa_feat[...,0] - of_extra_msa_feat).abs().mean())\n",
    "\n",
    "my_batch = {\n",
    "    'msa_feat': msa_feat.float(),\n",
    "    'extra_msa_feat': extra_msa_feat.float(),\n",
    "    'target_feat': target_feat.float(),\n",
    "    'residue_index': residue_index.float()\n",
    "}\n",
    "\n",
    "torch.save(my_batch, 'kilian/my_batch.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openfold_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
