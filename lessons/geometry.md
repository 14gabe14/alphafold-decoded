# Geometry

<!-- Live -->
Hi everyone, and welcome to this video on three dimensional geometry. I'm Kilian Mandon and this video is the seventh in our series where we'll be implementing AlphaFold from scratch. 

In the following two videos, we'll finish off the series by implementing the Structure Module and putting all the parts together. As preparation for this, we'll need some advanced geometry to get back from the tensors we can output from a machine learning model, to actual atom positions.
<!-- End Live -->

We'll start with a quick overview. AlphaFold has two types of outputs to create the atom positions: The first is the backbone output. For each amino acid, AlphaFold predicts three scalar values as the x, y and z coordinates of the translation, and a quaternion that encodes the backbone's orientation, consisting of four scalar values. We'll learn what this is shortly. All atom positions, mostly those of the sidechain, are constructed relative to the backbone transform from seven torsion angles: The backbone torsion angles omega, phi and psi, and the sidechain angles chi1 to chi4. Depending on the type of amino acid and its sidechain length, not all four sidechain angles are used in the construction. The angles aren't directly predicted, rather, they are predicted as a two element vector and scaled down to a length of 1, then interpreted as cosine and sine of the angle. 

We dont really need an elaborate architecture to get this type of output. Basically, we only need a total of 21 values for each residue, and structurally, we could get that by simply following up on the single representation from the Evoformer with a 384 to 21 channel linear layer. What's a bit involved is actually reconstructing the molecules from these values. 

<!-- Live -->
If you stumbled across some advanced geometry before, you're probably already aware of nice methods to represent rotations, namely rotation matrices. If so, you might be a little surprised why we're using quaternions here, given that they aren't the standard text-book choice for rotations. The basic answer is, Quaternions are particularly suitable as output for neural networks, and here's why.
<!-- End Live -->

When choosing output formats for continuous output from neural networks - that is, output that shouldn't just be as high as possible vs as low as possible, but where the actual value matters - the optimal output format is generally one where the typical distribution of the output is an independent gaussian distribution. Weight initialization methods, like xavier initialization or He initialization are chosen so that at the start of training, layer outputs are just that: indepent standard gaussian distributions. If this is a somewhat sensible output for the model, it's easier for it to learn the changes it has to make to adopt the output to the input. 

For the translation of the backbone, it seems a good choice to directly predict xyz coordinates. Proteins are generally globular, so you would expect individual amino acid positions to be spherically uniform distributed, and with a tendency towards the center.

When it comes to rotations, the situation becomes more complex. Predicting using Euler angles, for instance, would result in a non-uniform distribution, leading to uneven coverage of orientations, even though a uniform distribution is typically desired.

It turns out that quaternions are the perfect fit for that: A quaternion consists of four values, and if it's used to represent a rotation, it should have length one. By just sammpling four random, gaussian values, and scaling the vector to have length one afterwards, we get a uniform distribution over all possible rotations. We won't go into the details of why this works out, but basically, the xyz coordinates of a quaternion determine its rotational axis. Choosing these spherically random, we get a uniform distribution for the axis of rotation, and if you do the math, this method also gives a uniform distribution over the angle of rotation around this axis.

The same trick is used for the torsion angles, and there, it's a little easier to understand as well. If you just directly predicted the angles, a gaussian distribution would favor angles close to 0. Instead, the model predicts two coordinates and scales them down to the unit circle. After scaling down, the x and y parts of the vector are interpreted as cosine and sine of the angle, and we can calculate the angle using arcrtan, for example. Since the gaussian distribution is spherically random, in doing so, we get a uniform distribution over the torsion angles. 

Knowing this, let's get into the details of how all of this actually works.

A transform, like the transform of the backbones, consists of two parts: A rotation, or orientation, of the frame, and a translation. Transforms are used to position objects in 3 dimensional space. An object is generally a set of points, defined relative to its origin. A mathematical model of a transform needs to specify a mapping from the local coordinates of the object to the positions they are at after applying the transform. 

In this video, we'll cover three parts: First, we will understand how to model rotations, using both quaternions and rotation matrices, as we'll use both in AlphaFold. 

Second, we'll look at how we model transforms, that is rotations and translations, and how we can compose multiple transforms. In particular, we'll look at the benefits of using homogenous coordinates for transforms.

Last, we'll see how we use these methods to actually construct the full amino acids from the networks output we've seen before, the translation, the rotation, and the torsion angles. This last step will put the basics we learned before together to implement the method "compute_all_atom_coordinates" from the AlphaFold paper.

We'll start with rotation matrices. The basic concept of rotation matrices is to specify where the three basic unit vectors, 100, 010 and 001, will point to after the rotation. Basically, any set of three vectors is valid, as long as they are orthonormal, that is orthogonal and normalized to length one, and oriented in a right-handed fashion. A right-handed fashion means that if you use the thumb, index and middle finger of your right hand and orient them so that the thumb points in x-direction and the index finger points in y-direction, the middle finger should point in z-direction. 

If you know these three vectors, you can simply put them as columns in a matrix, and this is the rotation matrix: Multiplication of a vector with it will rotate the vector according to the rotation that's specified by the new positions of the basis vectors. You can easily check that this holds true for the standard basis vectors: If you multiply R with 100, you get ex', which is the correct result. Since rotation is a linear operation, if you multiply R with a combination of the basis vectors, like with the vector 012, the output of the operation, which is the same combination of the new basis vectors, will also be the correctly rotated vector. 

One thing to note here is that, if you have a frame, and its rotated in a specific way, we don't really need to know the z-direction of the vectors to know the rotation. x and y already define that its somewhere on this line, because its the only one that's orthogonal to both, and with the constraint of being right-handed and of length one, z is fully determined by x and y. There even is a simple mathmatical formula to calculate z from x and y and its called the cross product of the two. For two orthogonal vectors, the cross product is the vector orthogonal to both in a right-handed fashion, with its magnitude being the product of the magnitudes of the two original vectors. This makes its magnitude one in this case. Spelled out, the calculation of the cross product looks like this. It's pretty simple to calculate by hand, and most libraries like PyTorch already implement it anyway. 

But, going on from leaving out z, we dont even need x and y to be orthogonal either. If we start out with two vectors x and v, that are not orthogonal to each other, we can easily reconstruct y. As long as the vectors dont lie on one line, we know that y should be somewhere on the plane they span up, meaning it should be a linear combination of x and v. More detailed it should be the vector in the plane, that is orthogonal to x. We can calculate it, by first calculating the part of v that's parallel to x. With x having length 1, this is the dot product of v and x, times x. Knowing this, we can construct the orthogonal part by substracting the parallel part from v. To construct y, all we need to do is scale it to unit length. 

This approach is called the Gram-Schmidt-Orthonormalization of the two vectors. To prove it, all you need to check is that v perp and x are orthogonal, which you can do by checking that their dot product is 0. If v_perp is actually orthogonal, its the correct solution, because we already know that its in the correct plane, since its a linear combination of x and v.

This is a method we'll explicitly use in AlphaFold to construct 3x3 Rotation matrices from two, possibly non-orthogonal, vectors. Spelled out in code, it looks like this. First, we normalize ex. Then, we substract ex scaled by the dot-product of the two from ey. ey is normalized and afterwards, we calculate ez as the cross product. Finally, we stack the three vectors as columns in a matrix. 

There's one important consequence of this construction, and its about the rotation's inverse. If we start with a matrix R consisting of three orthonormal vectors u v and w, and we multiplicate R against its transposed, by the rules of matrix multiplication - calculating the dot product of each row with each column - the result is this: On the diagonal, we have the dot product of each vector with itself, and off the diagonal we have mixed dot products. Since the vectors are orthogonal, the mixed dot products are 0, and since they have unit length, the self-dot-products are 1. This means that a rotation matrix's transposed is its inverse.
Going over to transforms, which means rotation plus a translation vector t, the inverse of the transform consists of the transposed rotation matrix and the tranlation "minus R transposed times t". 

With this, we know everything about rotation matrices we need to know: They consist of three orthonormal vectors, oriented in a right-handed fashion. We can construct them from two non-orthogonal vectors using gram-schmidt orthonormalization and the cross product, and its inverse is its transposed. Next, we'll go on two quaternions.

Basically, a quaternion's idea is even more natural than that of a rotation matrix. A quaternion directly describes a rotation by a rotational axis, and an angle by which a vector is rotated around the axis. We can do a pretty straight-forward geometric construction to come up with what this vector should be. 

To do so, the first thing to see is that its enough to consider a vector v thats perpendicular to n. If its not so, we can decompose it into its parallel part and its orthogonal part. The rotated version can be reconstructed by simply adding the parallel part to the rotated orthogonal part.

Knowing this, we start of with a rotation axis n of unit length, and a perpendicular vector v. What we want to calculate is the rotated version v'. To do so, we first need a vector that helps with the construction: The vector nxv, that's orthogonal to n and v in a right-handed fashion. With this helping vector, constructing v' is basic trigonometry: The part of it that points in the direction of v is cos(theta) times the norm of v. Norm v is the length of the hypothenuse of the triangle, since v prime and v have the same length, and by multiplying it with cos(theta) we get the length of the adjacent, which is the side we want. The amount to which v' points into the direction of nxv is the opposite of the triangle. By trigonometry, this is sin(theta) times norm nxv, since nxv has the same length as v' and v by the rules of the cross product. Note that from the right-hand-rule for the cross-product, we also inherit a right-hand rule for the direction of the rotation: If you point your right thumb in the direction of n and curl up the other fingers, the rotation follows the direction of your fingers.

With the trigonometric argument, we've got the magnitudes of v' in these coordinates, and since the directions of the axes are v and nxv, we know that we can construct v' as cos(theta) v + sin(theta) nxv. 

Basically, quaternions are defined to implement exactly this equation. A quaternion q consists of a scalar part q0 and a vector part. The multiplication of two quaternions q and p is defined as follows: The scalar part is the product of the scalar parts minus the dot product of the vector parts. For the vector part of the result, we calculate the sum of three terms: scalar of q times vector of p, scalar of p times vector of q and vector of q cross vector of p. Just from the definition you can see that quaternions dont commute, that is q\*p isnt equal to p\*q, since the cross product itself isnt commutative. 

To model rotation, we do as follows: We create a rotation quaternion q with scalar part cos(theta) and vector part sin(theta) times the unit vector n, which serves as the rotatinoal axis. Note that with this construction, q has unit length. It's true the other way around as well: Every unit length quaternion can be written in this form. 
For the vector v that we want to rotate, we promote it to a quaternion by padding it with the scalar part 0. If we do so and calculate the product of q and v using the formula above, we end up with a quaternion with scalar part 0 and vector part v'. Note that the dot product of n and v in the calculation is zero because they are orthogonal.

So, we know how we can perform rotation of an orthogonal vector around an axis: We construct the rotation quaternion q with cos(theta) and sin(theta) times n, and we promote the vector to a quaternion by padding it with scalar 0. Now, the rotated vector is simply the vector part of the quaternion product of the two. 

We also discussed how we can use this for general, non-orthogonal rotationl. We simply decompose the vector into its orthogonal and parallel part, which we can do with the gram-schmidt process we have seen earlier, and then construct the rotated version as the sum of the rotated orthogonal part and the parallel part.

There is, however, a trick, with which we can perform general rotation even easier. To use it, we need to also consider the conjugate quaternion q star, which is the same as q but with the sign of the vector part flipped. As a small side note, this is also the inverse of q: You can see that because it's simply rotation around n by -theta, if you take the properties of cosine and sine into account. 

Now, using both q and q\*, with theta/2 as the angle, the following hold true: For a vector v perp that is perpendicular to n, the product q times vperp times q\* results in the orthogonal part of v prime, rotated by the full angle theta. On the other hand, computing q times vparallel times q\* on a parallel vector simply leaves it unchanged. With this, applying this product to vperp + vparallel, which is just v, results in the rotated version of vperp + vparallel, which is exactly the rotated version of the full vector. This means, using this double-sided multiplication and only half of the angle, we can rotate any vector v, even if its not orthogonal. 

This seems somewhat counterintuitive, and the fact that quaternion rotation works like this can be hard to spot. One of the rare opportunities where you have direct contact to quaternions is when using game engines like unity. I think its interesting to see how they handle this fact: Here, I've got a small example script in unity that constructs a quaternion as a rotation of 90 degrees around the x-axis. In addition, the script prints out reference values of cosine at 90 degrees and 45 degrees. 

When executing the script, you can see that the actual values in the quaternion agree with the construction using half-angles, that is the scalar part is cos(45˚). Going back to the script, we can also see how the rotation of a vector by the quaternion uses the two-sided multiplication. Here, we print out three values: First, the result of direct multiplication of the quaternion q against the vector v. Second the multiplication of q times v as quaternions, with v promoted to a quaternion with scalar part 0, and third, the double sided quaternion multiplicaiton, also using the manually embedded quaternion v. Looking at the results of this, the quaternion vector multiplication actually equals the third result, the double-sided multiplication. I myself was pretty confused after learning about quaternions why i can do rotation in unity by simply multiplying the quaternion with the vector, given that this only works for orthogonal vectors, until i found out that in reality, unity just translates quaternion vector multiplication into two-sided quaternion multiplication. 

The two properties we needed for the construction were the behaviour of orthogonal and parallel vectors under two-sided multiplication. There isn't any particular magic to the proof, but the terms are a bit messy. I spelled them out for you, so if you're interested, you can pause the video and read through them. This here is the proof for the orthogonal part. It uses the double-angle formulas for sine and cosine and two properties of the cross product, which you can deduce by checking them with the right hand rule. 
Here, you can see the proof for the parallel part. The scalar part and the vector part of the result are denoted as its real and imaginary part. This is typical for quaternions, originating in their notation as four-dimensional complex numbers. 

A piece of quaternion math that's a little less messy is thinking about the conversion of quaternions to rotation matrices and vice versa. Both are pretty straightforward: For the construction of rotation matrices, we just need to know the position of the three basic axes 100, 010 and 001. So, all we need to do is apply the quaternion to them by the two-sided multiplication we've seen before, then stack the results as columns in a matrix. 

For the opposite direction, we first need to find the axis of rotation. This is the one vector that isn't affected by the matrix but stays still. In mathematics, this is called an eigenvector with eigenvalue 1, and there exist simple methods for the calculation of eigenvectors. Knowing the axis of rotation, we can simply choose a unit vector w that is orthogonal to v - for example by choosing a random vector and performing orthonormalization using gram-schmidt. Having found such an orthonormal vector w, we can just multiplicate it against the matrix and calculate the angle between the rotated and unrotated version, using the dot-product formula.

We dont need matrix-to-quaternion conversion, but we will use the quaternion to matrix conversion in AlphaFold. One thing to note is that you dont need to work with actual values for the quaternion but you can also perform the operation algebraically. This is how the conversion is performed in the AlphaFold paper, in Algorithm 23. After normalizing the network output so that the quaternion is actually a rotation quaternion with unit length, the values are gathered in a matrix in line 3. This line looks like black magic on first glance, but its just the algebraic result of performing the quaternion-matrix conversion from the last slide with a quaternion q consisting of the values a,b,c, and d. 

You can do this conversion for some specific quaternions as well - for example for ones with the rotational axis being the standard axes. In doing so, we get these basic rotation matrices, which you might have seen before in another context. Of those, we'll use the first variant, rotation around the x-axis, to apply the torsion angles to the coordinate frames. We'll see about that later.

For the next part of the video, we'll move on from rotations to transforms, that is rotation and translation. For an object, defined by its coordinates relative to its local frame, we already know how we can transform the points: The transformed points are, using rotation matrices, Rx+t. There are two ways to think about the application of this transform. The first is the perspective we just looked at: Applying the transform means moving the object from its previous position. The second interpretation works just as well and is more descriptive in many cases. For this, we consider the object as previously observed in its local space. Now, applying the transform means actually considering the object in a more global frame, by changing perspective. This interpretation is well-suited for AlphaFold, where we construct the atom positions in the local backbone frame, then apply the backbone transform to globalize them. 

Another concept that's useful and necessary for AlphaFold is composition of multiple transforms. Mathematically, this simply means applying the second transform to the already rotated point R1x+t1. If we start of with an object that's defined by a combination of two transforms and we want to introduce a third transform, we have two options: The first is doing left-side composition of the new transform. This has the consequence of applying the transform to the global position of the points, that is the points with the two previous transforms already applied. In doing so, we can have a strong leverage-effect from the rotation, if the points are pushed far from the origin by the first two transforms. 

Alternatively, we can introduce the new transform by right composition. This moves the local points of the object *before* they are transformed by the other two transforms. A slight update in local coordinates is generally less impactful on the global position of the object. In the backbone update, AlphaFold uses multiple iterations of the algorithm and concatenates the resulting transforms. It does so by concatenating the new transforms on the right-side, which is the more sensible approach for a less-strong leverage effect.

In terms of mathematics, a simple tool to handle rotation and translation more efficiently is the use of homogenous coordinates. To translate a vector to its homogenous form, you simply add an additional 1 as the fourth dimension. In homogenous coordinates, the vector is treated as scale invariant, meaning the vector xyz1 is identical to every scaled version of it (except if scaled by 0). To go back from homogenous coordinates to normal coordinates, the vector is simply scaled to have the value 1 as the last coordinate, then the first 3 coordinates are extracted. 

This use of a fourth dimension has the benefit of being able to express a transform, rotation plus translation, as simple matrix multiplication. For this to be the case, we construct the 4x4 transform matrix by concatenating R and t in this fashion, with a row of three zeros and a 1 at the bottom. If you check the operation, multiplication of the homogenous vector against T will lead to the transformed vector with an additional 1.

This formulation of applying a transform as simple matrix multiplication means that composition of tranforms is nothing but matrix multiplication. If we just used matrix multiplication plus vector addition instead, the term would be more complicated, and cumbersome to use without a wrapper object. In particular when using PyTorch with its strong support for basic tensor operations like batched matrix multiplication, using 4x4 transforms is preferrable and what we'll do in AlphaFold.

So far, we’ve seen how placing a matrix in the top-left quadrant and a vector in the right column allows us to perform matrix multiplication followed by vector addition. However, things get even more interesting when we make use of the bottom row. In homogeneous coordinates, transformations that modify this bottom row are known as perspective transformations. These are particularly relevant when working with 2D points in 3D homogeneous coordinates, as they simulate the effect of moving a camera and observing how the image changes. Perspective transformations have many practical applications. For instance, your phone’s panorama feature uses them to align individual frames, stitching them together into a seamless, wide-angle photo.

This behavior results from projecting a 3D object onto a 2D plane. Since we lack a practical fourth dimension in real life, perspective transformations aren’t commonly used in 4x4 transformations. However, it’s still possible you might encounter them in certain scenarios.

Closing off with the general geometric content, we come to the last topic for today: Actually constructing the coordinate frames and atom positions for the amino acids from the data AlphaFold outputs. With this, we'll implement the method compute_all_atom_coordinates from the AlphaFold paper. 

Shown here is the amino acid isoleucine. AlphaFold represents all coordinates in the amino acid relative to the amino acids backbone frame. The backbone frame is defined as sitting on the alpha C-atom with its x-axis pointing in the direction of the carbonyl C-atom and its y-axs pointing towards the nitrogen. You can see here why it was helpful to allow for non-orthogonal vectors in creation of the 3x3 rotation matrices earlier. We can simply use the bonds to define the axes, even though they form a tetraeder angle and not a 90˚ angle. 

Relative to the backbone frame, the carbonyl C is at a fixed position, 1.53 angstrom along the x-axis. The nitrogen atom is fixed as well, placed in the xy plane. The actual numbers for these positions where calculated from crystallography data, we'll look at the format in which we can access them later. 

AlphaFold additionally defines a frame, the so-called phi frame, for the nitrogen atom. This frame sits on the nitrogen atom with its x-axis pointing along the C-alpha to N bond and its y-axis pointing in the direction of the C-alpha to C bond. This frame isn't that important because there arent any heavy atoms positioned relative to it, only hydrogens, which alphafold doesn't predict. 

AlphaFold also places a frame, the psi-frame, on the carbonyl C, with its x-axis oriented along the C-alpha to C bond and its y-axis oriented along the N to C-alpha bond. This frame is more interesting because it actually defines the position of an atom, the carbonyl oxygen. Relative to the psi-frame, the oxygen lies in the xy plane. The phi-bond and the psi-bond can be freely rotated, and AlphaFold directly predicts these angles by their cosine and sine value. The frames where chosen so that their x-axis points in the bond-direction. This means that applying a rotation towards them simply means right-composition with a rotation matrix around the x-axis. This has the effect of rotating all atoms downstream of the frame around the local x-axis before they are globalized by the frames. 

The same method of nesting frames relative to the backbone frame is used to define the side-chain, using up to four side-chain frames and their torsion angles. The first side-chain frame is placed on the beta C-atom, its x-axis oriented along the side-chain bond and its y-axis oriented along the C-alpha to N bond. Again, the x-axis is oriented along the bond that the torsion angle is affecting, and we can model rotation by right-composition with a rotation matrix around the x-axis. The next and all following side-chain frames are defined with the x-axis pointing along the bond direction, that is C-beta to C-gamma, and the y-axis pointing along the previous bond, that is C-beta to C-alpha. In doing so, the x-axis is pointing along the bond direction again. Note that all atoms used to create and orient the next frame - in this case C-gamma, C-beta and C-alpha - must be fixed and known in the coordinates relative to the parent frame - in this case the chi1 frame. For the backbone frame and the chi1 frame this was the case, since all of the backbone atom positions are defined relative to the backbone frame. For creation of the chi2 frame, the gamma and beta C atoms are directly known in chi1 coordinates: C-gamma because it's defined in this coordinate system in the data we are using, and C-beta because its at 0 0 0. C-alpha isn't defined in the coordinates of C-beta, but we know that we constructed the frame with its x-axis pointing along the bond. This means we know the direction from C-beta towards C-alpha is (-1, 0, 0).

The positioning and construction of the individual frames is a bit involved, but you'll have concrete information on handling the data in the jupyter notebook. The atomic position data you'll work with is formated like this. This is the part for isoleucine, which is the amino acid we just looked at. All atom positions are defined by an atom name, the frame index they are positioned relative to, and the position in this frame. The frame index 0 is the backbone frame. Frame index 3, in which the oxygen lies, is the psi-frame, 4 is the chi1 frame and 5 is the chi2 frame. From this data, we directly compute the backbone frames and the side-chain frames.

Shown here is the method in which we compute the backbone frames. In addition to the backbone group, the phi group and the psi group, we also create the pre-omega group. This is mostly a placeholder, because there aren't any atoms in it anyway. It would be used if we placed the next amino acid relative to the current one, but we dont - we predict its backbone transform directly as well. Relative to the backbone, the backbone-group and pre-omega-group have the identiy transform, which means no motion. For 4x4 transforms, this is a matrix with 1 on the diagonal and 0 elsewhere. The docstring states what the vectors for the x and y direction and the translation of the phi and psi groups should be. You can see that this positioning agrees with the placement of the frames we just discussed. Looking at the atom data, we can check that all atom positions used are given relative to the backbone frame, which needs to be the case so that we can use them to position the new frames relative to the backbone group. When all is done, the method returns a tensor of shape (20, 4, 4, 4), consisting of the 4 4x4 backbone frames for the 20 amino acids. 

For the side-chain frames, the concept is mostly the same. The only thing that changed is that we additionally need to know the atoms that lie along the sidechain, so that we can access their positions. These are given in the form of a side-chain list. For isoleucine for example, they are C-beta and C-gamma-1. These are sufficient to create the first two side-chain frames, which are all we need to define the positions of all atoms in isoleucine. Here, not all atoms used to define the transforms are in the correct frame. Concretely, the target atoms for the ey axis - Ca, side-chain atom 0 and side-chain atom 1 for the three last frames respectively - aren't defined relative to the direct parent frame. When defining chi2 for example, the atom C-alpha is defined relative to frame index 0, which is the backbone group, instead of the chi1 group that's the direct parent of chi2. Here, we use the trick that by definition of our transforms, the ey-axis orientation is always (-1, 0, 0), since the x-axis of the parent frame is always oriented along the bond direction. 

With these two methods, we can construct all coordinate frames for the case that all bond angles are 0. In the next method, compute_global_transforms, we apply the torsion angles and the backbone transforms for the amino acid. To understand how we do this, it's important to pay a close look to the function's signature, that is its arguments and what it returns. The function takes three arguments. The backbone transforms T are of shape (N_res, 4, 4). They are simply global 4x4 transforms to position every residue in the protein. The torsion angles, named alpha, have shape (N_res, 7, 2). For each residue and for each of its up to 7 torsion angles, it consists of two values, specifying the angle's cosine and sine. And last, we have the label vector F of shape (N_res), which contains labels from 0 to 19 to state the type of amino acid at each residue positions. This is used to know which static frames we need to use for each residue. In the end, the method returns the eight global frames of shape (N_res, 8, 4, 4) for each residue. 

In the method body, first we use the previously defined functions to calculate the transforms for the 20 amino acids for the case that all torsion angles are 0. We select the relevant frames for our protein by indexing into the transforms with our label vector F, to retrieve the correct local frames for each residue. Then, we simply compute the global transforms by composition of the global backbone transform T, the precalculated local transform and a transform that rotates around the x-axis. For the side-chain frames, this is mostly the same. However, we don't use the backbone transform T but the previously calculated global transform of the last side-chain frame for the calculation.

Having calculated all the global frames for each residue, we can use those in the final method, compute_all_atom_coordinates. It has the same arguments as compute_global_transforms, but it has different return values. First, it returns global_positions of shape (N_res, 37, 3). In AlphaFold, we define up to 37 different heavy atoms for each amino acid, and each atom is defined by its 3-dimensional position. Additionally, we return an atom_mask of shape (N_res, 37). This is a boolean array stating which of the 37 atoms are actually present for each of the residues. 

In the body of compute_all_atom_coordinates, we first calculate the global frames using the method we just discussed. Then, we retrieve a list of local positions and which frames they are relative to for each atom in each amino acid. We use the label vector F to extract the data for the amino acids that are in our protein. Then, we use the frame indices to select the correct global frames for each atom. Using homogenous coordinates, we can apply the transforms to the atom positions by batched matrix-vector multiplication, which is done here using torch.einsum. Note that we left out the steps for padding with 1 and removing it afterwards, to promote the positions to homogenous coordinates and back. Last, we can select the atom_mask from the per-amino-acid atom_mask using the label vector. 

This was a bit of a messy end for an otherwise really general video on geometry, but I hope it will help you when you're actually doing the implementation in the acompanying jupyter notebook. The notebook won't only do the AlphaFold implementation, but it will also let you implement the geometry concepts. I hope you liked the math as much as I did. In any case, good luck with the notebook and happy coding!